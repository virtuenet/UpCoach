# UpCoach LLM Server Environment Configuration

# API Security
LLM_API_KEY=your-secure-api-key-here

# Model Configuration
VLLM_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# Rate Limiting
RATE_LIMIT_RPM=60

# Caching
CACHE_TTL=3600

# Logging
LOG_LEVEL=info

# Server Ports (internal, modify docker-compose for external)
GATEWAY_PORT=3100
OLLAMA_PORT=11434
VLLM_PORT=8000
REDIS_PORT=6379

# GPU Configuration (for vLLM production profile)
GPU_MEMORY_UTILIZATION=0.9
TENSOR_PARALLEL_SIZE=1
