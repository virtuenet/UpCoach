# UpCoach LLM Server - Development Environment Configuration
# Copy this file to .env for local development

# =============================================================================
# API Security
# =============================================================================

# API key for gateway authentication (optional in dev)
LLM_API_KEY=dev-local-key-12345

# =============================================================================
# Model Configuration
# =============================================================================

# Primary model for vLLM (production profile)
VLLM_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# Default model for requests without model specified
DEFAULT_MODEL=mistral

# =============================================================================
# Rate Limiting
# =============================================================================

# Requests per minute limit (higher for dev)
RATE_LIMIT_RPM=120

# =============================================================================
# Caching
# =============================================================================

# Response cache TTL in seconds (shorter for dev)
CACHE_TTL=300

# =============================================================================
# Logging
# =============================================================================

# Log level: debug, info, warn, error
LOG_LEVEL=debug

# =============================================================================
# Server Ports
# =============================================================================

# LLM Gateway port
GATEWAY_PORT=3100

# Ollama port
OLLAMA_PORT=11434

# vLLM port (production only)
VLLM_PORT=8000

# Redis port
REDIS_PORT=6379

# =============================================================================
# GPU Configuration (if available)
# =============================================================================

# GPU memory utilization (0.0 - 1.0)
GPU_MEMORY_UTILIZATION=0.8

# Tensor parallelism (number of GPUs)
TENSOR_PARALLEL_SIZE=1

# =============================================================================
# Ollama Settings
# =============================================================================

# Allow connections from any origin
OLLAMA_ORIGINS=*

# Number of parallel requests
OLLAMA_NUM_PARALLEL=4

# Maximum models loaded simultaneously
OLLAMA_MAX_LOADED_MODELS=2

# =============================================================================
# Redis Settings
# =============================================================================

# Redis URL for caching and rate limiting
REDIS_URL=redis://localhost:6379

# Redis max memory
REDIS_MAXMEMORY=256mb

# =============================================================================
# Development Features
# =============================================================================

# Enable request/response logging
ENABLE_REQUEST_LOGGING=true

# Enable mock responses for testing
ENABLE_MOCK_MODE=false

# Skip API key validation
SKIP_AUTH=true
